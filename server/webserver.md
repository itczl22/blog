高并发的程序一般使用同步非阻塞+io多路复用的方式, 而非多线程+同步阻塞方式.  

内核提供了阻塞I/O("从网络连接中读取并把数据给我")和非阻塞I/O("当这些网络连接有新数据时就告诉我")这两种方法. 而使用何种机制, 对应调用过程的阻塞时间明显长度不同. 假设非阻塞系统调用可能需要9纳秒这样数量级的周期才能完成, 对于正在通过网络接收信息的阻塞调用可能需要90毫秒. 对于阻塞调用, 你的程序多等待了100万倍的时间.  

一般来说系统调用是阻塞的[read], 然而有些调用被分类为'非阻塞'[select、epoll_wait], 意味着内核接收了你的请求后把它放进了队列或者缓冲的某个地方, 然后立即返回而并没有等待实际的I/O调用.  


#### php vs golang

比如php的同步阻塞模型: 一个请求, 一个进程, I/O是阻塞的, 一个请求处理完再处理下一个. 优点是简单、可行. 缺点是由于内核提供的用于处理大容量I/O（epoll等）的工具没有被使用, 并发上不来, 一旦请求量高了就会出现大面积等待进而超时失败  

8核16G的机器一般起256个php-fpm, 对于php如果一个请求block住了, 该进程就会被block住, 导致后边达到该进程的请求全部阻塞, 相当于有一个php-fpm被堵住了, 流量如果不下降被阻塞的请求就会越来越多, 这样其处理能力必然下降了.  

但是go不同, 哪怕某个请求被阻塞了并不影响后边请求的处理, 因为go可以开启成千上万的携程, 所以某个请求的携程被阻塞了并不影响其他请求的处理, 这也是为什么golang的吞吐率更高的原因.   

但是如果在机器性能ok的情况下, go服务的最大连接数设置的不合理, 连接数达到最大值依然会出现阻塞的现象. 以及系统最大打开文件描述符的限制(线上设置的都是1M=1048576).  

Go提供的网络接口在用户层是阻塞的, 这样最符合人们的编程习惯. 在runtime层面, 是用epoll/kqueue实现的非阻塞io, 为性能提供了保障.  

底层非阻塞io是如何实现的呢？简单地说, 所有文件描述符都被设置成非阻塞的, 某个goroutine进行io操作, 读或者写文件描述符, 如果此刻io还没准备好, 则这个goroutine会被放到系统的等待队列中, 这个goroutine失去了运行权[但是php就会一直卡在这直到数据返回]. 后台还有一个poller会不停地进行poll, 所有的文件描述符都被添加到了这个poller中的, 当某个时刻一个文件描述符准备好了, poller就会唤醒之前因它而阻塞的goroutine, 于是goroutine重新运行起来.  

协程的调度需要消耗CPU, 协程切换时的上下文保存需要消耗内存. 比如Golang在协程goroutine之间同步数据(全局变量)需要使用channel甚至lock, 而在PHP-FPM进程里读写PHP全局变量, 根本不需要考虑同步和加锁的问题, 因为他不需要做同步和切换. 这也就是非高并发的情况下多进程处理的速度比使用io多路复用更快. golang的优势是处理高并发的场景, 而不是单个请求, 单个请求的话反而没有同步阻塞来的快.  

其实在正常的非高并发的业务场景中，也有类似的情况出现，某个业务请求接口出现问题，响应时间极慢，将整个Web请求响应时间拉得很长，逐渐将Web服务器的可用连接数占满，其他正常的业务请求，无连接进程可用. 之前腾讯新闻评论大面积失败就是因为后端服务超时导致网关连接数占满而拒绝掉后续请求, 处理能力急速下降. 所以后端的超时尽可能的设置合理, 不要过大, 这样即使后端服务出问题可以通过超时时间即时断开连接. 更可怕的问题是用户的行为，系统越是不可用，用户的点击越频繁，恶性循环最终导致"雪崩"(其中一台Web机器挂了, 导致流量分散到其他正常工作的机器上, 再导致正常的机器也挂, 然后恶性循环), 将整个Web系统拖垮.


io阻塞时会让出cpu的, 如果一个CPU内核运行在2GHz, 在没有优化的情况下它每秒执行2亿次循环(或者每纳秒2次循环). 如果上游服务超时导致上下游服务连接数占满, 下游机器的cpu和负载都会下降, 内存使用率会增加.  
